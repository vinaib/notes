-------------------------------------------------------------------------------
# Memory types and attributes and the memory order model
-------------------------------------------------------------------------------
# ARMv6 defined a set of memory attributes with the characteristics required to
  support the memory and devices in the system memory map. 

# In ARMv7 this set of attributes is extended by the addition of the Outer
  Shareable attribute for Normal memory and, in an implementation that does not
  include the Large Physical Address Extension, for Device memory.

# Whether an ARMv7 implementation distinguishes between Inner Shareable and
  Outer Shareable memory is IMPLEMENTATION DEFINED.

# Normal memory that is Inner Non-cacheable, Outer Non-cacheable is inherently
  coherent between different processors, and it is IMPLEMENTATION DEFINED
  whether such memory, if it does not have the Shareable attribute, is treated
  as Non-shareable or as Shareable.
-------------------------------------------------------------------------------
# Memory Types
-------------------------------------------------------------------------------
# For each memory region, the most significant memory attribute specifies the
  memory types
# There are three mutually exclusive memory types:
## Normal
## Device
## Strongly-ordered
-------------------------------------------------------------------------------
# Shareability
-------------------------------------------------------------------------------
# Inner Shareable
## Normal memory
## Device memory with out LPAE only

# Outer Shareable
## Normal memory
## Device memory with LPAE only

# Non Shareable
-------------------------------------------------------------------------------
# Cacheability
-------------------------------------------------------------------------------
# Only to Normal memory
-> Cacheable
-> Non Cacheable
-> Inner non cacheable
-> Outer non cacheable

Note:
Normal memory that is Inner Non-cacheable, Outer Non-cacheable is inherently
coherent between different processors, and it is IMPLEMENTATION DEFINED whether
such memory, if it does not have the Shareable attribute, is treated as
Non-shareable or as Shareable.

-------------------------------------------------------------------------------
Memory type  Implementation includes LPAE a ?  Shareability  	Cacheability
-------------------------------------------------------------------------------
Strongly	  	- 								- 					NonCacheable
Device 			Yes 							Outer Shareable 	NonCacheable
Device 			No	 							Outer Shareable 	NonCacheable
Device 			No  							Inner Shareable 	NonCacheable
Device 			No  							Non   Shareable 	NonCacheable
Normal			-								Outer Shareable		One of:
Normal			-								Inner Shareable		NonCacheable
Normal			-								Non   Shareable		WriteThrough
																	WriteBack
------------------------------------------------------------------------------------
[ref]: https://developer.arm.com/documentation/ddi0211/k/memory-management-unit/memory-attributes-and-types

-> Normal - Shared - Noncacheable/ Write-Through Cacheable/ Write-Back Cacheable - Designed to handle normal memory that is shared between several processors.
-> Normal - Non-Shared - Noncacheable/ Write-Through Cacheable/ Write-Back Cacheable - Designed to handle normal memory that is used only by a single processor.
-> Device - Shared - Designed to handle memory-mapped peripherals that are shared by several processors.
-> Device - Non-Shared - Designed to handle memory-mapped peripherals that are used only by a single processor.
-> Strongly Ordered - All memory accesses to Strongly Ordered memory occur in program order. All Strongly Ordered accesses are assumed to be shared.

-------------------------------------------------------------------------------
# Normal Memory
-------------------------------------------------------------------------------
Usually, memory used for programs and for data storage is suitable for access
using the Normal memory attribute.

# Accesses to normal memory region are idempotent, meaning that they exhibit the
  following properties
1) read accesses can be repeated with no side-effects
2) repeated read accesses return the last value written to the resource being
   read
3) read accesses can fetch additional memory locations with no side-effects
4) write accesses can be repeated with no side-effects in the following cases
  a) if the contents of the location accessed are unchanged between the repeated
  writes.
  b) as the result of an exception, as described in this section
5) unaligned accesses can be supported
6) accesses can be merged before accessing the target memory system.

# Normal memory can be read/write or read-only
# Normal memory region is defined as being either Shareable or Non-shareable
  1) For Shareable Normal memory:
  # whether a VMSA implementation distinguishes between InnerShareable and Outer
    Shareable is IMPLEMENTATION DEFINED.
  # A PMSA implementation makes no distinction between Inner Shareable and Outer
    Shareable regions.

# Normal memory type attribute applies to most memory used in a system.
# The cacheability and cache allocation hint attributes apply only to Normal
memory
(Device and Strongly-ordered memory regions are Non-cacheable.)
# Applies only to Normal memory, and can be defined independently for Inner and
Outer cache regions.

-----------------------------------------------------------------------------
Shareable, Inner Shareable, and Outer Shareable Normal memory Attributes
-----------------------------------------------------------------------------
# Shareable attribute in Shareable domain:
------------------------------------------
A region of Normal memory with the Shareable attribute is one for which data
accesses to memory by different observers within the same shareability domain
are coherent.

# Inner shareable attribute:
----------------------------
In a VMSA implementation, Normal memory that has the Shareable attribute but not
the Outer Shareable attribute assigned is described as having the Inner
Shareable attribute.

Example:
In a VMSA implementation, a particular subsystem with two clusters of processors
has the requirement that In each cluster, the data or unified caches of the
processors in the cluster are transparent for all data accesses with the Inner
Shareable attribute.

In this system, each cluster is in a different shareability domain for the Inner
Shareable attribute.

This architecture is written with an expectation that all processors using the
same operating system or hypervisor are in the same Inner Shareable shareability
domain.

# Outer shareable attribute:
----------------------------
In a VMSA implementation, a particular subsystem with two clusters of processors
has the requirement that, between the two clusters, the caches:
— are not transparent for data accesses that have only the Inner Shareable
attribute.
— are transparent for data accesses that have the Outer Shareable attribute.

but all components of the subsystem are in the same shareability domain for the
Outer Shareable attribute.

Shareability Domains:
----------------------
The shareable attributes can define sets of observers for which the shareability
attributes make the data or unified caches transparent for data accesses. The
sets of observers that are affected by the shareability attributes are described
as shareability domains.

--------------------------------------------------------------------------------
Write-Through Cacheable, Write-Back Cacheable and Non-cacheable Normal memory
--------------------------------------------------------------------------------
Normal memory cacheability attribute that is one of:
• Write-Through Cacheable
• Write-Back Cacheable
• Non-cacheable

** -> The cacheability attributes provide a mechanism of coherency control with
observers that lie outside the shareability domain of a region of memory.

The ARM architecture provides independent cacheability attributes for Normal
memory for two conceptual levels of cache, 
-> the inner cacheability
inner refers to the innermost caches, and always includes the lowest level of
cache.
-> the outer cacheability

Transient cacheability attribute, Large Physical Address Extension:
If an implementation supports this attribute, the set of possible cacheability
attributes for a Normal memory region becomes:
• Write-Through Cacheable, Non-transient
• Write-Back Cacheable, Non-transient
• Write-Through Cacheable, Transient
• Write-Back Cacheable, Transient
• Non-cacheable.

Transient:
The transient attribute indicates that the benefit of caching is for a
relatively short period, and that therefore it might be better to restrict
allocation, to avoid possibly casting-out other, less transient, entries.

--------------------------------------------------------------------------------
Memory types and aatributes and Memory order model	
--------------------------------------------------------------------------------
The ordering of accesses for regions of memory, referred to as the memory order
model, is defined by the memory attributes.
-> see above table
-> Atomicity in Arm Arch
--> single copy atomicity:
In ARMv7, the single-copy atomic processor accesses are:
• all byte accesses
• all halfword accesses to halfword-aligned locations
• all word accesses to word-aligned locations
• memory accesses caused by LDREXD and STREXD instructions to doubleword-aligned
locations
• In an implementation that includes the Large Physical Address Extension, 
LDRD and STRD accesses to 64-bit aligned locations are 64-bit single-copy atomic
as seen by translation table walks and accesses to translation tables.
• instructions are executed as a sequence of word-aligned word accesses. 
• Each 32-bit word access is guaranteed to be single-copy atomic.
LDM:
LDC: 
LDC2: 
LDRD: 
STM: 
STC: 
STC2: 
STRD: 
PUSH: 
POP: 
RFE: 
SRS: 
VLDM: 
VLDR: 
VSTM: 
VSTR:
--> If, according to these rules, an instruction is executed as a sequence of
accesses, some exceptions can be taken during that sequence. Such an exception
causes execution of the instruction to be abandoned.
-> If any of these exceptions are returned from using their preferred return
address, the instruction that generated the sequence of accesses is re-executed
and so any access that had been performed before the exception was taken is
repeated.

--> Instruction fetches are single-copy atomic:
— at 32-bit granularity in ARM state
— at 16-bit granularity in Thumb and ThumbEE states
— at 8-bit granularity in Jazelle state.

--> Translation table walks are performed using accesses that are single-copy
atomic:
— at 32-bit granularity when using Short-descriptor format translation tables
— at 64-bit granularity when using Long-descriptor format translation tables.

-> Multi-copy atomicity
In a multiprocessing system, writes to a memory location are multi-copy atomic
if the following conditions are both true:
• All writes to the same location are serialized, meaning they are observed in
the same order by all observers, although some observers might not observe all
of the writes.
• A read of a location does not return the value of a write until all observers
observe that write.
• Writes to Normal memory are not multi-copy atomic. All writes to Device and
• Strongly-ordered memory that are single-copy atomic are also multi-copy atomic
• All write accesses to the same location are serialized. 
• Write accesses to Normal memory can be repeated up to the point that another
write to the same address is observed.
• For Normal memory, serialization of writes does not prohibit the merging of
writes.

-> In general, for Normal memory, 
--> barrier operations are required where the order of memory accesses observed
by other observers must be controlled.
--> This requirement applies regardless of the cacheability and shareability
attributes of the Normal memory region.

-> The architecture permits speculative accesses to memory locations marked as
Normal if the access permissions and domain permit an access to the locations.

Non-shareable Normal memory
---------------------------
-> For a Normal memory region: 
--> the Non-shareable attribute identifies Normal memory that is likely to be
accessed only by a single processor.
--> A region of Normal memory with the Non-shareable attribute does not have any
requirement to make data accesses by different observers coherent.

-----------------------------------------------------------------------------
if Normal Memory is shared with other observers: (Cache maintenance + barrier
instructions)
-----------------------------------------------------------------------------
--> software must use cache maintenance operations if the presence of caches
might lead to coherency issues when communicating between the observers.

--> This cache maintenance requirement is in addition to the barrier operations
that are required to ensure memory ordering.

--------------------------------------------------------------------------------
what is sepculative data access?
--------------------------------------------------------------------------------
Speculation (also known as speculative loading ), is a process implemented in
processors and their compilers to reduce processor-memory exchanging bottlenecks
or latency by putting all the data into memory in advance of an actual load
instruction.

Speculative execution is an optimization technique where a computer system
performs some task that may not be needed.

Work is done before it is known whether it is actually needed, so as to prevent
a delay that would have to be incurred by doing the work after it is known that
it is needed. 

If it turns out the work was not needed after all, most changes made by the work
are reverted and the results are ignored.

The objective is to provide more concurrency if extra resources are available. 

This approach is employed in a variety of areas, including branch prediction in
pipelined processors, value prediction for exploiting value locality,
prefetching memory and files, and optimistic concurrency control in database
systems.
--------------------------------------------------------------------------------
Device/Strongly ordered memory
--------------------------------------------------------------------------------
1) Examples of memory regions normally marked as being Device or
Strongly-ordered memory are Memory-mapped peripherals and I/O locations.

2) The architecture does not permit speculative data accesses to memory marked
as Device or Strongly-ordered.

3) Address locations marked as Device or Strongly-ordered are never held in a
cache.

4) Address locations marked as Strongly-ordered, 
and on an implementation that includes the Large Physical Address Extension, 
address locations marked as Device, are always treated as Shareable.

5) No LPAE
-> On an implementation that does not include the Large Physical Address
Extension, the shareability of an address location marked as Device is
configurable.

-> On an implementation that does not include the Large Physical Address
Extension, the requirements for Device memory depend on the shareability of the
Device memory locations.

6) All explicit accesses to Device or Strongly-ordered memory must comply with
the ordering requirements of accesses described in Ordering requirements for
memory accesses.

7) The architecture does not permit unaligned accesses to Strongly-ordered or
Device memory.

8) a write to Strongly-ordered memory can complete only when it reaches the
peripheral or memory component accessed by the write.

9) a write to Device memory is permitted to complete before it reaches the
peripheral or memory component accessed by the write.

Shareable attribute for Device memory regions:
----------------------------------------------
When implementation has no LPAE:
-> Device memory regions can be given the Shareable attribute
-> This means that a region of Device memory can be described as one of:
• Outer Shareable Device memory
• Inner Shareable Device memory
• Non-shareable Device memory

# Some implementations make no distinction between Outer Shareable Device memory
and Inner Shareable Device memory, and refer to both memory types as Shareable
Device memory.

# Some implementations make no distinction between Shareable Device memory and
Non-shareable Device memory, and refer to both memory types as Shareable
Device memory.

For Device memory regions, the significance of shareability is IMPLEMENTATION
DEFINED. 

However, an example of a system supporting Shareable and Non-shareable
Device memory is an implementation that supports both:
• a local bus for its private peripherals
• system peripherals implemented on the main shared system bus.

--------------------------------------------------------------------------------
Device and Strongly-ordered memory shareability, Large Physical Address
Extension
--------------------------------------------------------------------------------
-> In an implementation that includes the Large Physical Address Extension, the
Long-descriptor translation table format does not distinguish between Shareable
and Non-shareable Device memory.

-> In an implementation that includes the Large Physical Address Extension and
is using the Short-descriptor translation table format:

--> An address-based cache maintenance operation for an addresses in a region
with the Strongly-ordered or Device memory type applies to all processors in the
same Outer Shareable domain, regardless of any shareability attributes applied
to the region.

--> Device memory transactions to a single peripheral must not be reordered,
regardless of any shareability attributes that are applied to the
corresponding Device memory region. Any single peripheral has an
IMPLEMENTATION DEFINED size of not less than 1KB.

--------------------------------------------------------------------------------
Privilege level access controls for data accesses
--------------------------------------------------------------------------------
PL0:
----
1) The privilege level of application software, that executes in User mode
2) software executed in User mode is described as unprivileged software and 
makes only unprivileged memory accesses.
3) it cannot change many of the architecture configuration settings

PL1:
----
1) operating system software executes at PL1.
2) Software executing at PL1 can access all features of the architecture, and
can change the configuration settings for those features.
3)  it cannot configure Virtualization Extensions which are only accessible at
PL2.
4) Software executing at PL1 makes privileged memory accesses by default, but
can also make unprivileged accesses.

PL2:
----
1) Software executing in Hyp mode executes at PL2
2) Software executing at PL2 can perform all of the operations accessible at
PL1, and can access some additional functionality
3) Hyp mode is normally used by a hypervisor, that controls, and can switch
between, Guest OSs, that execute at PL1.
4) Hyp mode is implemented only as part of the Virtualization Extensions, and
only in Non-secure state. This means that:
• implementations that do not include the Virtualization Extensions have only
two privilege levels, PL0 and PL1
• execution in Secure state has only two privilege levels, PL0 and PL1.

Imp Points:
----------
# EPL defined independently for each mode:
In an implementation that includes the Security Extensions, the execution
privilege levels are defined independently in each security state, and there is
no relationship between the Secure and Non-secure privilege levels.

# Superior Secure:
The fact that Non-secure Hyp mode executes at PL2 does not indicate that it is
more privileged than the Secure PL1 modes. Secure PL1 modes can change the
configuration and control settings for Non-secure operation in all modes, but
Non-secure modes can never change the configuration and control settings for
Secure operation.

# Memory access permissions can be assigned:
• at PL1, for accesses made at PL1 and at PL0
• in Non-secure state, at PL2, independently for:
— Non-secure accesses made at PL2
— Non-secure accesses made at PL1, and at PL0.

1) The memory access permissions assigned at PL1 can define that a memory region
is: (if pt 2 is non secure then this should be superior secure)
• Not accessible to any accesses.
• Accessible only to accesses at PL1.
• Accessible to accesses at any level of privilege.(PL0, PL1, PL2)

2) In Non-secure state, separate memory access permissions can be assigned at
PL2 for:
• Accesses made at PL1 and PL0.
• Accesses made at PL2.

3) Data Abort: for data region
A Data Abort exception is generated if the processor attempts a data access
that the access rights do not permit. 

For example, a Data Abort exception is generated if the processor is at PL0 and
attempts to access a memory region that is marked as only accessible to
privileged memory accesses.

--------------------------------------------------------------------------------
Privilege level access controls for instruction accesses
--------------------------------------------------------------------------------
1) Memory attributes access permissions assigned at PL1 can define that a memory
region is: (if pt 2 is non secure then this is superior secure)
• Not accessible for execution.
• Not accessible for execution at PL1 Only implementations that include the
Large Physical Address Extension support this attribute.
• Accessible for execution only at PL1.
• Accessible for execution at any level of privilege. (PL0, PL1, PL2)

2) In Non-secure state, in an implementation that includes the Virtualization
Extensions, separate memory access permissions can be assigned at PL2 for:
• Accesses made at PL1 and PL0.
• Accesses made at PL2.

3) XN attribute: Exectue never
PXN: Privileged Execute never

4) Memory Abort: for code/instructions region
Any attempt to execute an instruction from a memory location with an
applicable execute-never attribute generates a memory fault.
------------------------------------------------------------------------------------------
Memory access order
------------------------------------------------------------------------------------------
1) When considering memory access ordering, an important feature of the ARMv7
memory model is the Shareable memory attribute, that indicates whether a region
of memory appears coherent for data accesses made by multiple observers.

The key issues with the memory order model depend on the target audience:
• For software programmers: 
considering the model at the Application level, the key factor is that for
accesses to Normal memory barriers are required in some situations where the
order of accesses observed by other observers must be controlled.

• For silicon implementers:
considering the model at the system level, the Strongly-ordered and Device
memory attributes place certain restrictions on the system designer in terms of
what can be built and when to indicate completion of an access.

Reads and writes:
-> Each memory access is either a read or a write. 
-> Explicit memory accesses are the memory accesses required by the function of
an instruction: LDR, LDRB ....
-> The following are not explicit memory accesses:
• instruction fetches
• cache loads and write-backs
• translation table walks

**-> the memory ordering requirements only apply to explicit memory accesses

Observer:
---------
-> Local observer
-> global observer: with in a Shareability domain

Completion:
-----------
1) A read or write is complete for a shareability domain when all of the
following are true:
— the read or write is globally observed for that shareability domain
— any translation table walks associated with the read or write are complete for
that shareability domain.

2) A translation table walk is complete for a shareability domain when the
memory accesses associated with the translation table walk are globally observed
for that shareability domain, and the TLB is updated.

3) A cache, branch predictor, or TLB maintenance operation is complete for a
shareability domain when the effects of the operation are globally observed for
that shareability domain, and any translation table walks that arise from the
operation are complete for that shareability domain.

The completion of any cache, branch predictor or TLB maintenance operation
includes its completion on all processors that are affected by both the
operation and the DSB operation that is required to guarantee visibility of the
maintenance operation.

Memory order requirements:
--------------------------
1) There are no ordering requirements for implicit accesses to any type of memory

2) The following additional restrictions apply to the ordering of all memory
accesses(explicit):

-> Uniprocessor:
----------------
# For all accesses from a single observer, the requirements of uniprocessor
semantics must be maintained, for example:
— respecting dependencies between instructions in a single processor
— coherency.

# If there is an address dependency then the two memory accesses are observed in
program order by anyobserver in the common shareability domain of the two
accesses.

# If the value returned by a read access is used as data written by a subsequent
write access, then the two memory accesses are observed in program order by
any observer in the common shareability domain of the two accesses.

# It is impossible for an observer in the shareability domain of a memory
location to observe an access by a store instruction that has not been
architecturally executed.

# It is impossible for an observer in the shareability domain of a memory
location to observe two reads to the same memory location performed by the
same observer in an order that would not occur in a sequential execution of a
program

# For an implementation that does not include the Multiprocessing Extensions,
it is IMPLEMENTATION DEFINED whether all writes complete in a finite period of
time, or whether some writes require the execution of a DSB instruction to
guarantee their completion.

# For an implementation that includes the Multiprocessing Extensions, all writes
complete in a finite period of time.

# If A1 and A2 are two word loads generated by an LDC-class or LDM-class  or
LDRD instruction, or two word stores generated by an STC-class or STM-class
instruction or STRD, excluding LDM-class and STM-class instructions with a
register list that includes the PC, the program order of the memory accesses is
not defined.

------------------------------------------------------------------------------------------
Memory barriers
------------------------------------------------------------------------------------------
-> Memory barrier is the general term applied to an instruction, or sequence of
instructions, that forces synchronization events by a processor with respect to
retiring load/store instructions.

-> The ARM architecture defines a number of memory barriers that provide a range
of functionality, including:
• ordering of load/store instructions
• completion of load/store instructions
• context synchronization

-> In ARMv7 the memory barriers are provided as instructions that are available
in the ARM and Thumb instruction sets.

-> In ARMv6 the memory barriers are performed by CP15 register writes

-> The three memory barriers are:
• Data Memory Barrier
• Data Synchronization Barrier
• Instruction Synchronization Barrier

Note:
Depending on the required synchronization:
-> a program might use memory barriers on their own, or 
-> it might use them in conjunction with cache and memory management maintenance
operations that are only available when software execution is at PL1 or higher.
-> Instruction fetches or accesses caused by a hardware translation table access
are not explicit accesses.

Synchronization is required only for explicit access not for implicit access
(like instruction fetches or TT walk)

The DMB and DSB memory barriers affect reads and writes to the memory system
generated by load/store instructions and data or unified cache maintenance
operations being executed by the processor.
--------------------------------------------------------------------------------
DMB: Data Memory Barrier
--------------------------------------------------------------------------------
-> A DMB creates two groups of memory accesses, Group A and Group B
Pe: Executing processor

-> Group A contains (before DMB):
# All explicit memory accesses from observers in the same required shareability
domain as Pe that are observed by Pe before the DMB instruction.
# All loads of required access types from an observer Px in the same required
shareability domain as Pe that have been observed by any given different
observer, Py, in the same required shareability domain as Pe before Py has
performed a memory access that is a member of Group A.

-> Group B contains (after DMB):
# All explicit memory accesses of the required access types by Pe that occur in
program order after the DMB instruction.
# All explicit memory accesses of the required access types by any given
observer Px in the same required shareability domain as Pe that can only occur
after a load by Px has returned the result of a store that is a member of
Group B.

-> DMB only affects memory accesses and data and unified cache maintenance
operations

-> It has no effect on the ordering of any other instructions executing on the
processor.

--------------------------------------------------------------------------------
Data Synchronization Barrier (DSB)
--------------------------------------------------------------------------------
-> The DSB instruction is a special memory barrier, that synchronizes the
execution stream with memory accesses.

-> A DSB behaves as a DMB with the same arguments, and also has the additional
properties defined here. A DSB completes when:
--> all explicit memory accesses that are observed by Pe before the DSB is
executed are complete for the set of observers in the shareability domain.
--> all cache and branch predictor maintenance operations issued by Pe before
the DSB are complete for the shareability domain.
--> if the required accesses types of the DSB is reads and writes, all TLB
maintenance operations issued by Pe before the DSB are complete for the
shareability domain.

-> In addition, no instruction that appears in program order after the DSB
instruction can execute until the DSB completes.

-> Historically, this operation was referred to as Drain Write Buffer or Data
Write Barrier (DWB). From ARMv6, use of DWB were deprecated in favor of the new
DSB. DSB better reflects the functionality provided from ARMv6, because DSB is
architecturally defined to include all cache, TLB and branch prediction
maintenance operations as well as explicit memory operations.
--------------------------------------------------------------------------------
Instruction Synchronization Barrier (ISB)
--------------------------------------------------------------------------------
-> An ISB instruction flushes the pipeline in the processor, so that all
instructions that come after the ISB instruction in program order are fetched
from cache or memory only after the ISB instruction has completed.

-> Using an ISB ensures that the effects of context-changing operations executed
before the ISB are visible to the instructions fetched after the ISB
instruction.


--------------------------------------------------------------------------------
The DMB and DSB instructions can each take an optional argument that specifies
--------------------------------------------------------------------------------
• the shareability domain over which the instruction must operate, as one of:
— full system R/W				(SY)
- full system Write only 		(ST)
— Outer Shareable R/W			OSH
— Outer Shareable write only	OSHST
— Inner Shareable R/W 			ISH
— Inner Shareable write only	ISHST
— Non-shareable R/W				(NSH)
— Non-shareable	write only		(NSHST)

• the accesses for which the instruction operates, as one of:
— read and write accesses
— write accesses only.

--------------------------------------------------------------------------------
ISB 
--------------------------------------------------------------------------------
-> ISB also supports an optional limitation argument, but supports only one
value for that argument, that corresponds to full system operation.

