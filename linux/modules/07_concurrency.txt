--------------------------------------------------------------------------------
Race conditions
--------------------------------------------------------------------------------
# Race conditions are a result of uncontrolled access to shared data (or)
# Race conditions come about as a result of shared access to resources.

Sources of concurrency:
----------------------
# Multiple user space are running, they can access your code in surprising
  combinations of ways.
# SMP systems can be executing code simultaneously on diffrent processors
# kernel code is preemptible: your drivers code can lose the processor at any
  time and the process that replaces it could also be running in your driver.
# Device interrupts are asynchronous events that can cause concurrent execution
  of your code
# The kernel also provides various mechanisms for delayed code execution, such
 as workqueues, tasklets, and timers, which can cause your code to run at any
 time
# Due to hot pluggable: your device could simply disappear in middle of working
  with it.

Principles for avoiding race conditions
---------------------------------------
1) first rule of thumb: (Avoid shared resources, use of global variables)
-> to keep on mind as you design your driver is to avoid shared resources
whenever possible. If there is no concurrent access, there can be no race
conditions.	So carefully written kernel code should have a minimum of sharing.
Themost obvious application of this idea is to avoid the use of global
variables.

If you put a resource in a place where more than one thread of execution can
find it, there should be a strong reason for doing so.

2) Other important rule to consider is, when kernel code creates an object that
will be shared with any other part of the kernel, that object must continue to
exist (and function properly) until it is known that no outside references to it
exist.

Two requirements come out of this rule: no object can be made available to the
kernel until it is in a state where it can function properly, and references to
such objects must be tracked. In most cases, you’ll find that the kernel handles
reference counting for you, but there are always exceptions.

Mechansims to avoid race conditions:
-----------------------------------
# if there are any shared data, make operations on that data atomic, meaning
 that the entire operation happens at once. 

 To achieve this, we must setup critical sections: code that can be executed by
 only one thread at any given time.

# not all critical sections are the same.

# shared data between two process:
--------------------------------- 
> we can use a locking mechanism that might cause the other process to sleep
 while waiting for access to the critical section.

> while performing an operation, memory allocation with kmalloc, process could
  sleep. 

> we must use a locking primitive that works when a thread that owns the lock
  sleeps.

> Not all locking mechanisms can be used where sleeping is a possibility  

> For our present needs however, the mechanism that fits best is a semaphore.
 
Semaphores
----------
> semaphore is a single integer value combined with a pair of functions that are
 typically called P and V.
> A process wishing to enter a critical section will call P on the relevant
 semaphore; if the semaphore’s value is greater than zero, that value is
 decremented by one and the process continues.
> If, instead, the semaphore’s value is 0 (or less), the process must wait until
 somebody else releases the semaphore.
> Unlocking a semaphore is accomplished by calling V; this function increments
 the value of the semaphore and, if necessary, wakes up processes that are
 waiting.

Mutual exclusion/Mutex
----------------------
> When semaphore value is set to 1, such a semaphore can be held only by a
 single process or thread at any given time.
> semaphore used in this mode is sometimes called a mutex, an abbreviation of
 mutual exclusion.
> Almost all semaphores found in the Linux kernel are used for mutual exclusion

Linux implementation <asm/semaphore.h>
---------------------------------------
> The relevant type is struct semaphore; actual semaphores can be declared and
 initialized in a few ways. One is to create a semaphore directly, then set it
 up with sema_init:

 void sema_init(struct semaphore *sem, int val);
 # val is the initial value to assign to a semaphore.

 Kernel also provides a set of helper functions and macros, thus a mutex can be
 declared and initialized with one of the following:

 DECLARE_MUTEX(name); semaphore variable (called name ) that is initialized to 1

 DECLARE_MUTEX_LOCKED(name); variable initialized with 0.
 with this mutex starts out in a locked state.

> if mutex must be initialized at runtime, use one of the following:
  void init_MUTEX(struct semaphore *sem);
  void init_MUTEX_LOCKED(struct semaphore *sem);

> in linux P function is "down". Holding a semaphore
> V function is "up". Releasing a semaphore

 Variations of down:
--------------------
# void down(struct semaphore *sem);
down decrements the value of the semaphore and waits as long as need be.

# int down_interruptible(struct semaphore *sem);
down_interruptible does the same, but the operation is interruptible. The
interruptible version is almost always the one you will want; it allows a
user-space process that is waiting on a semaphore to be interrupted by the user.
however, if the operation is interrupted, the function returns a nonzero
value, and the caller does not hold the semaphore. 
Proper use of down_interruptible requires always checking the return value and
responding accordingly.

# int down_trylock(struct semaphore *sem);
The final version (down_trylock) never sleeps; if the semaphore is not available
at the time of the call, down_trylock returns immediately with a nonzero return
value.

up
----
# void up(struct semaphore *sem);
Once up has been called, the caller no longer holds the semaphore.

Any thread that takes out a semaphore is required to release it with one (and
only one) call to up. 

Special care is often required in error paths; if an error is encountered while
a semaphore is held, that semaphore must be released before returning the error
status to the caller.

--------------------------------------------------------------------------------
Reader/Writer Semaphores: <linux/rwsem.h>
--------------------------------------------------------------------------------
-> Allows multiple concurrent readers, as long as nobody is trying to make any
changes.

-> An rwsem allows either one writer or an unlimited number of readers to hold
the semaphore.

Writers get priority; as soon as a writer tries to enter the critical section,no
readers will be allowed in until all writers have completed their work. This
implementation can lead to reader starvation where readers are denied access for
a long time. if you have a large number of writers contending for the semaphore.

-> rwsems are best used when write access is required only rarely, and writer
access is held for short periods of time.

-> linux kernel provides a special type of semaphore called a rwsem for this
situation. The use of rwsems in drivers is relatively rare.

-> struct rw_semaphore
   void init_rwem(struct rw_semaphore *sem);

-> An initialized rwsem is available for usage.

--------------------------------------------------------------------------------
Interface for read only access, possibly concurrently with other readers.
--------------------------------------------------------------------------------
void down_read(struct rw_semaphore *sem);
int down_read_trylock(struct rw_semaphore *sem);
void up_read(struct rw_semaphore *sem);

-> Note that down_read may put the calling process into an uninterruptible
sleep.

-> down_read_trylock will not wait if read access is unavailable.it returns
nonzero if access was granted, 0 otherwise.

-> freed with up_read

--------------------------------------------------------------------------------
Interface for writer
--------------------------------------------------------------------------------
void down_write(struct rw_semaphore *sem);
int down_write_trylock(struct rw_semaphore *sem);
void up_write(struct rw_semaphore *sem);
void downgrade_write(struct rw_semaphore *sem);

-> down_write, down_write_trylock, and up_write all behave just like their
reader counterparts, except, of course, that they provide write access.

-> If you have a situation where a writer lock is needed for a quick change,
followed by a longer period of read-only access, you can use downgrade_write
to allow other readers in once you have finished making changes.

--------------------------------------------------------------------------------
Completions: <linux/completion.h>
--------------------------------------------------------------------------------
A common pattern in kernel programming involves initiating some activity outside
of the current thread, then waiting for that activity to complete.

Completions are a lightweight mechanism with one task: allowing one thread to
tell another that the job is done.

Interface:
-> DECLARE_COMPLETION(my_completion);
-> if the completion must be created and initialized dynamically:
	struct completion my_completion;
	init_completion(&my_completion);
-> Waiting for the completion is a simple matter of calling
	void wait_for_completion(struct completion *c);
-> this function performs an uninterruptible wait. If your code calls wait_for_
completion and nobody ever completes the task, the result will be an unkillable
process.
-> completion event may be signalled by calling one of the following:
void complete(struct completion *c);
void complete_all(struct completion *c);

-> A completion is normally a one-shot device; it is used once then discarded.

-> It is possible, however, to reuse completion structures if proper care is
taken.

-> The macro INIT_COMPLETION(sturct completion c) can be used to quickly perform
this reinitialization.

--------------------------------------------------------------------------------
Spinlock: <linux/spinlock.h>
--------------------------------------------------------------------------------
-> A spinlock is a mutual exclusion device that can have only two values:
“locked” and “unlocked.”.

-> It is usually implemented as a single bit in an integer value.

-> Code wishing to take out a particular lock tests the relevant bit. If the
lock is available, the “locked” bit is set and the code continues into the
critical section. If, instead, the lock has been taken by somebody else, the
code goes into a tight loop where it repeatedly checks the lock until it becomes
available. This loop is the “spin” part of a spinlock.

-> the real implementation of a spinlock is a bit more complex than the
description above. The “test and set” operation must be done in an atomic
manner so that only one thread can obtain the lock, even if several are spinning
at any given time.

-> when there is contention for a spinlock, the processors that are waiting
execute a tight loop and accomplish no useful work.

-> Spinlocks are, by their nature, intended for use on multiprocessor systems

-> although a uniprocessor workstation running a preemptive kernel behaves like
SMP, as far as concurrency is concerned.

-> If a nonpreemptive uniprocessor system ever went into a spin on a lock, it
would spin forever; no other thread would ever be able to obtain the CPU to
release the lock.

-> For this reason, spinlock operations on uniprocessor systems without
preemption enabled are optimized to do nothing, with the exception of the ones
that change the IRQ masking status.

Interface:

# Compile time:
spinlock_t my_lock = SPIN_LOCK_UNLOCKED;

# run time:
void spin_lock_init(spinlock_t *lock);

# Before entering a critical section, your code must obtain the requisite lock with
void spin_lock(spinlock_t *lock);

# Note that all spinlock waits are, by their nature, uninterruptible. Once you
 call spin_lock, you will spin until the lock becomes available.

# To release a lock that you have obtained, pass it to: 
 void spin_unlock(spinlock_t *lock);

--------------------------------------------------------------------------------
Spinlock and Atomic context (Rules)
--------------------------------------------------------------------------------
Rule 1: should be atomic
------------------------
Any Code holding a spinlock must be atomic. i.e. it cannot sleep. It cannot
relinquish the processor for any reason except to serivce interrupts and
sometimes not even then.

Avoiding sleep while holding a lock can be more difficult; many kernel functions
can sleep, and this behavior is not always well documented.

Scenario 1:
Copying data to or from user space is an obvious example: the required
user-space page may need to be swapped in from the disk before the copy can
proceed, and that operation clearly requires a sleep.

Scenario 2:
Any operation that must allocate memory can sleep; kmalloc can decide to give up
the processor, and wait for more memory to become available unless it is
explicitly told not to.

Rule 2: Preemption disabled
---------------------------
Code holding a lock and a higher-priority process pushes your code aside (due to
kernel preemption). If some other thread tries to obtain the same lock, it will,
in the best case, wait (spinning in the processor) for a very long time. 
In the worst case, the system could deadlock entirely.

Any time kernel code holds a spinlock, preemption is disabled on the relevant
processor. Even uni-processor systems must disable preemption in this way to
avoid race conditions. That is why proper locking is required even if you never
expect your code to run on a multiprocessor machine.

Rule 3: Interrupts disbaled on local CPU
----------------------------------------
Your driver is executing and has just taken out a lock that controls access to
its device. While the lock is held, the device issues an interrupt, which causes
your interrupt handler to run. The interrupt handler, before accessing the
device, must also obtain the lock. Taking out a spinlock in an interrupt handler
is a legitimate thing to do; that is one of the reasons that spinlock operations
do not sleep. But what happens if the interrupt routine executes in the same
processor as the code that took out the lock originally? While the interrupt
handler is spinning, the noninterrupt code will not be able to run to release
the lock. That processor will spin forever.

Rule 4: spinlock must always be held for minimum possible time
--------------------------------------------------------------
The longer you hold a lock, the longer another processor may have to spin
waiting for you to release it, and the chance of it having to spin at all is
greater.

Long lock hold times also keep the current processor from scheduling, meaning
that a higher priority process—which really should be able to get the CPU—may
have to wait (due to preemption disabled).

Variations of spinlock
-----------------------
-> void spin_lock(spinlock_t *lock);
   void spin_unlock(spinlock_t *lock);

-> void spin_lock_irq(spinlock_t *lock);
   void spin_unlock_irq(spinlock_t *lock);

-> void spin_lock_irqsave(spinlock_t *lock, unsigned long flags);
   void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);
spin_lock_irqsave disables interrupts (on the local processor only) before
taking the spinlock; the previous interrupt state is stored in flags.

You must also call spin_lock_irqsave and spin_unlock_irqrestore in the same
function; otherwise, your code may break on some architectures.

-> void spin_lock_bh(spinlock_t *lock);
   void spin_unlock_bh(spinlock_t *lock);
pin_lock_bh disables software interrupts efore taking the lock, but leaves
hardware interrupts enabled.

-> There is also a set of nonblocking spinlock operations:
int spin_trylock(spinlock_t *lock);
int spin_trylock_bh(spinlock_t *lock);

These functions return nonzero on success (the lock was obtained), 0 otherwise.
There is no “try” version that disables interrupts.

Rules
-----
If you have a spinlock that can be taken by code that runs in (hardware or
software) interrupt context, you must use one of the forms of spin_lock
that disables interrupts. Doing otherwise can deadlock the system, sooner or
later.

If you do not access your lock in a hardware interrupt handler, but you do via
software interrupts you can use spin_lock_bh to safely avoid deadlocks while
still allowing hardware interrupts to be serviced.

--------------------------------------------------------------------------------
Reader/Writer Spinlock: defined in <linux/spinlock.h>.
--------------------------------------------------------------------------------
These locks allow any number of readers into a critical section simultaneously,
but writers must have exclusive access. Reader/writer locks have a type of
rwlock_t.

They can be declared and initialized in two ways:
rwlock_t my_rwlock = RW_LOCK_UNLOCKED; /* Static way */

rwlock_t my_rwlock;
rwlock_init(&my_rwlock);  /* Dynamic way */

The list of functions available should look reasonably familiar by now. For readers,
the following functions are available:
void read_lock(rwlock_t *lock);
void read_lock_irqsave(rwlock_t *lock, unsigned long flags);
void read_lock_irq(rwlock_t *lock);
void read_lock_bh(rwlock_t *lock);

void read_unlock(rwlock_t *lock);
void read_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
void read_unlock_irq(rwlock_t *lock);
void read_unlock_bh(rwlock_t *lock);

there is no read_trylock.

The functions for write access are similar:
void write_lock(rwlock_t *lock);
void write_lock_irqsave(rwlock_t *lock, unsigned long flags);
void write_lock_irq(rwlock_t *lock);
void write_lock_bh(rwlock_t *lock);

int write_trylock(rwlock_t *lock);

void write_unlock(rwlock_t *lock);
void write_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
void write_unlock_irq(rwlock_t *lock);
void write_unlock_bh(rwlock_t *lock);

--------------------------------------------------------------------------------
Locking Traps
--------------------------------------------------------------------------------
When to create lock?

When you create a resource that can be accessed concurrently, you should define
which lock will control that access.

Scenario 1:
--------------
As you write several functions that all require access to structures protected
by a specific lock. At this point, you must be careful: if one function acquires
a lock and then calls another function that also attempts to acquire the lock,
your code deadlocks.

Neither semaphores nor spinlocks allow a lock holder to acquire the lock a
second time; should you attempt to do so, things simply hang.

Solution:
----------
1) To make your locking work properly, you have to write some functions with the
assumption that their caller has already acquired the relevant lock(s).

2) only your internal, static functions can be written in this way; 

3) functions called from outside must handle locking explicitly.

4) When you write internal functions that make assumptions about locking, do
yourself a favor and document those assumptions explicitly.

Example:
---------
In the case of scull, the design decision taken was to require all functions
invoked directly from system calls to acquire the semaphore applying to the
device structure that is accessed. All internal functions, which are only called
from other scull functions, can then assume that the semaphore has been properly
acquired.

Scenario 2:
------------
Taking multiple locks can be dangerous.

If you have two locks, called Lock1 and Lock2, and code needs to acquire both at
the same time, you have a potential deadlock.

Just imagine one thread locking Lock1 while another simultaneously takes Lock2.
Then each thread tries to get the one it doesn’t have. Both threads will
deadlock.

Solution:
---------
when multiple locks must be acquired, they should always be acquired in the same
order. As long as this convention is followed, simple deadlocks like the one
described above can be avoided.

A couple of rules of thumb can help:
1) If you must obtain a lock that is local to your code (a device lock, say)
along with a lock belonging to a more central part of the kernel, take your
lock first.

2) If you have a combination of semaphores and spinlocks, you must, of course,
obtain the semaphore(s) first; calling down (which can sleep).
otherwise if you obtain semaphore while holding spinlock it is a serious error.

3) try to avoid situations where you need more than one lock

Lockmeter
---------
If you do suspect that lock contention is hurting performance, you may find the
lockmeter tool useful. 
http://oss.sgi.com/projects/lockmeter/
 This patch instruments the kernel to measure time spent waiting in locks. By
looking at the report, you are able to determine quickly whether lock
contention is truly the problem or not.

Alternative to locking
-----------------------
Often there is no alternative to semaphores and spinlocks; they may be the only
way to get the job done properly. There are situations, however, where atomic
access can be set up without the need for full locking.

Lock free Algorithms: (ciruclar buffer)
----------------------------------------
If the writer takes care that the view of the data structure, as seen by the
reader, is always consistent, it may be possible to create a lock-free data
structure.

A data structure that can often be useful for lockless producer/consumer tasks
is the circular buffer.

This algorithm involves a producer placing data into one end of an array, while
the consumer removes data from the other.

When the end of the array is reached, the producer wraps back around to the
beginning.

So a circular buffer requires an array and two index values to track where the
next new value goes and which value should be removed from the buffer next.

* When carefully implemented, a circular buffer requires no locking in the
"absence" of multiple producers or consumers.

as of 2.6.10, there is a generic circular buffer implementation available in
the kernel; see <linux/kfifo.h> for information on how to use it.





